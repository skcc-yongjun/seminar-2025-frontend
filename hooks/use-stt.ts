import { useState, useRef, useCallback, useEffect } from "react"

/**
 * STT ê²°ê³¼ ì¸í„°í˜ì´ìŠ¤
 */
export interface STTResult {
  text: string
  position: number
  confidence: number
  full_text: string
  timestamp: string
}

/**
 * STT Hook ë°˜í™˜ íƒ€ì…
 */
export interface UseSTTReturn {
  isRecording: boolean
  isConnected: boolean
  transcript: string
  confidence: number
  error: string | null
  startRecording: () => Promise<void>
  stopRecording: () => void
  clearTranscript: () => void
}

/**
 * ì‹¤ì‹œê°„ STTë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ Hook
 * 
 * @param sessionId - ì„¸ì…˜ ID (ë°œí‘œì ì‹ë³„ìš©)
 * @param backendUrl - ë°±ì—”ë“œ WebSocket URL (ê¸°ë³¸ê°’: ws://localhost:8000)
 * @returns STT ê´€ë ¨ ìƒíƒœì™€ í•¨ìˆ˜ë“¤
 */
export function useSTT(
  sessionId: string,
  // ë¡œì»¬ ê°œë°œ: ws://localhost:8000
  // backendUrl: string = "ws://localhost:8000"
  // ë°°í¬ (HTTPS): wss://ceo-seminar-2025.skax.co.kr
  backendUrl: string = "wss://ceo-seminar-2025.skax.co.kr"
): UseSTTReturn {
  // ìƒíƒœ ê´€ë¦¬
  const [isRecording, setIsRecording] = useState(false)
  const [isConnected, setIsConnected] = useState(false)
  const [transcript, setTranscript] = useState("")
  const [confidence, setConfidence] = useState(0)
  const [error, setError] = useState<string | null>(null)

  // Refë¡œ ê´€ë¦¬í•  ê°ì²´ë“¤
  const wsRef = useRef<WebSocket | null>(null)
  const mediaStreamRef = useRef<MediaStream | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const processorRef = useRef<ScriptProcessorNode | null>(null)
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null)
  const isRecordingRef = useRef<boolean>(false) // í´ë¡œì € ë¬¸ì œ í•´ê²°ìš© ref

  /**
   * WebSocket ì—°ê²° ì„¤ì •
   */
  const connectWebSocket = useCallback((): Promise<WebSocket> => {
    return new Promise((resolve, reject) => {
      const wsUrl = `${backendUrl}/seminar/api/ws/stt/${sessionId}`
      const ws = new WebSocket(wsUrl)

      ws.binaryType = "arraybuffer"

      ws.onopen = () => {
        console.log("WebSocket ì—°ê²° ì„±ê³µ")
        setIsConnected(true)
        setError(null)
        resolve(ws)
      }

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data)

          if (data.type === "connected") {
            console.log("STT ì„œë¹„ìŠ¤ ì—°ê²°:", data.message)
          } else if (data.type === "transcription") {
            // STT ê²°ê³¼ ì—…ë°ì´íŠ¸
            setTranscript(data.full_text || data.text)
            setConfidence(data.confidence || 0)
          } else if (data.type === "completed") {
            console.log("STT ì™„ë£Œ:", data.message)
          } else if (data.type === "error") {
            console.error("STT ì˜¤ë¥˜:", data.message)
            setError(data.message)
          }
        } catch (err) {
          console.error("ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:", err)
        }
      }

      ws.onerror = (event) => {
        console.error("WebSocket ì˜¤ë¥˜:", event)
        setError("WebSocket ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        setIsConnected(false)
        reject(new Error("WebSocket ì—°ê²° ì‹¤íŒ¨"))
      }

      ws.onclose = () => {
        console.log("WebSocket ì—°ê²° ì¢…ë£Œ")
        setIsConnected(false)
      }

      wsRef.current = ws
    })
  }, [sessionId, backendUrl])

  /**
   * ì˜¤ë””ì˜¤ë¥¼ PCM í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   * CLOVA Speech APIëŠ” 16kHz, 1 Channel, 16-bit PCMì„ ìš”êµ¬
   */
  const convertToPCM = (audioData: Float32Array): Int16Array => {
    const pcmData = new Int16Array(audioData.length)
    
    for (let i = 0; i < audioData.length; i++) {
      // Float32 (-1.0 ~ 1.0)ë¥¼ Int16 (-32768 ~ 32767)ë¡œ ë³€í™˜
      const s = Math.max(-1, Math.min(1, audioData[i]))
      pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7fff
    }
    
    return pcmData
  }

  /**
   * ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë³€í™˜ (ë¦¬ìƒ˜í”Œë§)
   * ë§ˆì´í¬ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ 16kHzë¡œ ë³€í™˜
   */
  const resampleAudio = (
    audioData: Float32Array,
    inputSampleRate: number,
    outputSampleRate: number = 16000
  ): Float32Array => {
    if (inputSampleRate === outputSampleRate) {
      return audioData
    }

    const ratio = inputSampleRate / outputSampleRate
    const outputLength = Math.round(audioData.length / ratio)
    const result = new Float32Array(outputLength)

    for (let i = 0; i < outputLength; i++) {
      const position = i * ratio
      const index = Math.floor(position)
      const fraction = position - index

      // ì„ í˜• ë³´ê°„
      if (index + 1 < audioData.length) {
        result[i] = audioData[index] * (1 - fraction) + audioData[index + 1] * fraction
      } else {
        result[i] = audioData[index]
      }
    }

    return result
  }

  /**
   * ë…¹ìŒ ì‹œì‘
   */
  const startRecording = useCallback(async () => {
    try {
      setError(null)

      // 1. WebSocket ì—°ê²°
      const ws = await connectWebSocket()

      // 2. ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1, // ëª¨ë…¸
          sampleRate: 16000, // 16kHz (CLOVA Speech API ìš”êµ¬ì‚¬í•­)
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      })

      mediaStreamRef.current = stream

      // 3. Web Audio API ì„¤ì •
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000, // 16kHz
      })
      audioContextRef.current = audioContext

      const source = audioContext.createMediaStreamSource(stream)
      sourceRef.current = source

      // 4. ScriptProcessorNode ìƒì„± (ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬)
      const bufferSize = 4096 // ë²„í¼ í¬ê¸°
      const processor = audioContext.createScriptProcessor(bufferSize, 1, 1)
      processorRef.current = processor

      processor.onaudioprocess = (event) => {
        // refë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ìƒíƒœ í™•ì¸ (í´ë¡œì € ë¬¸ì œ í•´ê²°)
        if (!isRecordingRef.current || !ws || ws.readyState !== WebSocket.OPEN) {
          return
        }

        // ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        const inputData = event.inputBuffer.getChannelData(0)

        // ë¦¬ìƒ˜í”Œë§ (í•„ìš”í•œ ê²½ìš°)
        const resampledData = resampleAudio(
          inputData,
          audioContext.sampleRate,
          16000
        )

        // PCM ë³€í™˜
        const pcmData = convertToPCM(resampledData)

        // WebSocketì„ í†µí•´ ë°±ì—”ë“œë¡œ ì „ì†¡
        try {
          ws.send(pcmData.buffer)
          // console.log(`ğŸ¤ ì˜¤ë””ì˜¤ ì „ì†¡: ${pcmData.length} samples`)
        } catch (err) {
          console.error("ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜:", err)
        }
      }

      // 5. ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²°
      source.connect(processor)
      processor.connect(audioContext.destination)

      // refì™€ state ëª¨ë‘ ì—…ë°ì´íŠ¸
      isRecordingRef.current = true
      setIsRecording(true)
      console.log("ë…¹ìŒ ì‹œì‘")
    } catch (err) {
      console.error("ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:", err)
      setError(
        err instanceof Error
          ? err.message
          : "ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."
      )
      isRecordingRef.current = false
      setIsRecording(false)
    }
  }, [connectWebSocket])

  /**
   * ë…¹ìŒ ì¤‘ì§€
   */
  const stopRecording = useCallback(() => {
    console.log("ë…¹ìŒ ì¤‘ì§€")

    // ref ì—…ë°ì´íŠ¸ (ì˜¤ë””ì˜¤ ì „ì†¡ ì¦‰ì‹œ ì¤‘ë‹¨)
    isRecordingRef.current = false

    // WebSocket ì¢…ë£Œ ë©”ì‹œì§€ ì „ì†¡
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: "stop" }))
      wsRef.current.close()
    }

    // ì˜¤ë””ì˜¤ ë…¸ë“œ ì •ë¦¬
    if (processorRef.current) {
      processorRef.current.disconnect()
      processorRef.current = null
    }

    if (sourceRef.current) {
      sourceRef.current.disconnect()
      sourceRef.current = null
    }

    // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ
    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }

    // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì •ì§€
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop())
      mediaStreamRef.current = null
    }

    isRecordingRef.current = false
    setIsRecording(false)
    setIsConnected(false)
  }, [])

  /**
   * íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì´ˆê¸°í™”
   */
  const clearTranscript = useCallback(() => {
    setTranscript("")
    setConfidence(0)
  }, [])

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (isRecording) {
        stopRecording()
      }
    }
  }, [isRecording, stopRecording])

  return {
    isRecording,
    isConnected,
    transcript,
    confidence,
    error,
    startRecording,
    stopRecording,
    clearTranscript,
  }
}

